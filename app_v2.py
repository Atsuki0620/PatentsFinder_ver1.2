# --------------------------------------------
# 1. å…±é€šè¨­å®šãƒ»ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# --------------------------------------------
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
import re
import json
import pandas as pd
import numpy as np
from google.cloud import bigquery
from sklearn.metrics.pairwise import cosine_similarity
import os

# --- BigQuery/Embedding/é¡ä¼¼åº¦è¨ˆç®—ã®ãŸã‚ã®é–¢æ•°ç¾¤ ---

# è¨­å®šï¼ˆconfig.yamlã®ä»£æ›¿ï¼‰
# BQ_PROJECT ã¯èªè¨¼å¾Œã«ä¸Šæ›¸ãã•ã‚Œã‚‹
BQ_PUBLIC_PROJECT = "patents-public-data"
BQ_DATASET = "patents"
BQ_TABLE = "publications"
BQ_LOCATION = "US"
BQ_LIMIT = 100
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "text-embedding-ada-002")

# BigQueryã‹ã‚‰ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
def search_patents_by_params(params: dict) -> pd.DataFrame:
    # å…¬é–‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‚ç…§ç”¨ã«BQ_PUBLIC_PROJECT, BQ_LOCATIONã‚’åˆ©ç”¨
    client = bigquery.Client(project=BQ_PROJECT, credentials=GCP_CREDENTIALS, location=BQ_LOCATION)
    where = []
    if params.get("ipc_codes"):
        ipc_list = [f"'{c}'" for c in params["ipc_codes"]]
        where.append(f"ipc.code IN ({','.join(ipc_list)})")
    if params.get("countries"):
        if isinstance(params["countries"], list):
            countries = [f"'{c}'" for c in params["countries"]]
        else:
            countries = [f"'{params['countries']}'"]
        where.append(f"country_code IN ({','.join(countries)})")
    if params.get("assignees"):
        if isinstance(params["assignees"], list):
            assignees = [f"'{a}'" for a in params["assignees"]]
        else:
            assignees = [f"'{params['assignees']}'"]
        where.append(f"assignee IN ({','.join(assignees)})")
    if params.get("publication_from"):
        where.append(f"publication_date >= '{params['publication_from']}'")
    where_clause = " AND ".join(where) if where else "1=1"
    sql = f"""
        SELECT
            publication_number,
            (SELECT v.text FROM UNNEST(title_localized) AS v WHERE v.language='en' LIMIT 1) AS title,
            (SELECT v.text FROM UNNEST(abstract_localized) AS v WHERE v.language='en' LIMIT 1) AS abstract,
            publication_date,
            STRING_AGG(DISTINCT ipc.code, ',') AS ipc_codes,
            STRING_AGG(DISTINCT assignee_harmonized.name, ',') AS assignees
        FROM `{BQ_PUBLIC_PROJECT}.{BQ_DATASET}.{BQ_TABLE}` AS p
            LEFT JOIN UNNEST(p.ipc) AS ipc
            LEFT JOIN UNNEST(p.assignee_harmonized) AS assignee_harmonized
        WHERE {where_clause}
        GROUP BY publication_number, title, abstract, publication_date
        LIMIT {BQ_LIMIT}
    """
    df = client.query(sql).to_dataframe()
    return df

# ç‰¹è¨±ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆOpenAI APIä¾‹ï¼‰
def vectorize_texts(texts: list, openai_api_key: str) -> np.ndarray:
    import openai
    client = openai.OpenAI(api_key=openai_api_key)
    vectors = []
    for text in texts:
        resp = client.embeddings.create(input=text, model=EMBEDDING_MODEL)
        vectors.append(resp.data[0].embedding)
    return np.array(vectors)

# ã‚¯ã‚¨ãƒªã¨ç‰¹è¨±ãƒ™ã‚¯ãƒˆãƒ«ã®é¡ä¼¼åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°
def rank_by_similarity(query: str, patent_texts: list, openai_api_key: str) -> list:
    query_vec = vectorize_texts([query], openai_api_key)[0].reshape(1, -1)
    patent_vecs = vectorize_texts(patent_texts, openai_api_key)
    sims = cosine_similarity(query_vec, patent_vecs)[0]
    ranked_idx = np.argsort(sims)[::-1]
    return ranked_idx, sims

# --------------------------------------------
# 2. ãƒšãƒ¼ã‚¸è¨­å®šãƒ»ã‚¿ã‚¤ãƒˆãƒ«ãƒ»èª¬æ˜
# --------------------------------------------
st.set_page_config(page_title="ğŸ’¡ PatentsFinder_ver1.2 ãƒãƒ£ãƒƒãƒˆç‰ˆ", page_icon="ğŸ”")
st.title("ğŸ” PatentsFinder_ver1.2 - ãƒãƒ£ãƒƒãƒˆãƒ•ãƒ­ãƒ¼å®Ÿè£… (æ–¹é‡3)")
st.write(
    """
    ã“ã®ãƒãƒ£ãƒƒãƒˆç‰ˆã‚¢ãƒ—ãƒªã¯ã€å¯¾è©±å½¢å¼ã§ IPC ã‚³ãƒ¼ãƒ‰ã‚’ææ¡ˆã—ã€
    ãã®å¾Œãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œcountries, assignees, publication_fromã€ã‚’å…¥åŠ›ã™ã‚‹ã¨
    è‡ªå‹•çš„ã«JSONå½¢å¼ã®æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    """
)

# --------------------------------------------
# 3. API ã‚­ãƒ¼å…¥åŠ›
# --------------------------------------------
openai_api_key = st.text_input("OpenAI API Key", type="password")
openai_auth_ok = False
if openai_api_key:
    try:
        import openai
        openai.api_key = openai_api_key
        # v1.0.0ä»¥é™ã®èªè¨¼ç¢ºèª: embeddingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§ãƒ€ãƒŸãƒ¼ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        openai.embeddings.create(input="test", model="text-embedding-ada-002")
        st.success("OpenAI APIã‚­ãƒ¼ã®èªè¨¼ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        openai_auth_ok = True
    except Exception as e:
        st.error(f"OpenAI APIã‚­ãƒ¼ã®èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
else:
    st.info("ã¾ãšã¯ OpenAI API Key ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", icon="ğŸ—ï¸")
    st.stop()

gcp_json_str = st.text_area("Google Cloud ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ï¼ˆJSONã‚’è²¼ã‚Šä»˜ã‘ï¼‰", height=200)
gcp_auth_ok = False
if gcp_json_str:
    import io
    import json as _json
    try:
        gcp_info = _json.loads(gcp_json_str)
        from google.oauth2 import service_account
        GCP_CREDENTIALS = service_account.Credentials.from_service_account_info(gcp_info)
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’å–å¾—
        BQ_PROJECT = gcp_info.get("project_id")
        # BigQueryã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã§èªè¨¼ãƒ†ã‚¹ãƒˆ
        from google.cloud import bigquery
        client = bigquery.Client(project=BQ_PROJECT, credentials=GCP_CREDENTIALS)
        client.query("SELECT 1").result()
        st.success("Google Cloud ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        gcp_auth_ok = True
    except Exception as e:
        st.error(f"Google Cloud ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
else:
    st.info("BigQueryã‚’åˆ©ç”¨ã™ã‚‹ã«ã¯ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚­ãƒ¼ï¼ˆJSONï¼‰ã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„ã€‚", icon="ğŸ”‘")
    st.stop()

if not (openai_auth_ok and gcp_auth_ok):
    st.stop()

# --------------------------------------------
# 4. LangChain ã® LLM ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç”Ÿæˆ
# --------------------------------------------
llm = ChatOpenAI(
    model_name="gpt-4.1",
    openai_api_key=openai_api_key,
    temperature=0.2
)

# --------------------------------------------
# 5. ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–
# --------------------------------------------
if "messages" not in st.session_state:
    st.session_state.messages = []  # ä¼šè©±å±¥æ­´
if "ipc_candidates" not in st.session_state:
    st.session_state.ipc_candidates = []  # ææ¡ˆã•ã‚ŒãŸ IPC ã‚³ãƒ¼ãƒ‰
if "expect_search_params" not in st.session_state:
    st.session_state.expect_search_params = False  # æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¾…ã¡ãƒ•ãƒ©ã‚°
if "expect_tech_suggestion" not in st.session_state:
    st.session_state.expect_tech_suggestion = True  # æŠ€è¡“æ·±æ˜ã‚Šå¾…ã¡ãƒ•ãƒ©ã‚°
if "tech_suggested" not in st.session_state:
    st.session_state.tech_suggested = False  # æŠ€è¡“æ·±æ˜ã‚Šæ¸ˆã¿ãƒ•ãƒ©ã‚°
if "ipc_codes" not in st.session_state:
    st.session_state.ipc_codes = []
if "countries" not in st.session_state:
    st.session_state.countries = []
if "assignees" not in st.session_state:
    st.session_state.assignees = []
if "publication_from" not in st.session_state:
    st.session_state.publication_from = ""
if "search_ready" not in st.session_state:
    st.session_state.search_ready = False

# --------------------------------------------
# 6. é–¢æ•°å®šç¾©: IPC ã‚³ãƒ¼ãƒ‰ã‚’ææ¡ˆã—ã€è¿½åŠ æƒ…å ±ã‚’ä¿ƒã™è³ªå•ã‚’ã™ã‚‹
# --------------------------------------------
def generate_ipc_candidates(user_input: str):
    # ä¼šè©±å±¥æ­´ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ã‚’è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": user_input})

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
    system_prompt = """
    ã‚ãªãŸã¯ã€Œç‰¹è¨±èª¿æŸ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ã§ã™ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸæŠ€è¡“é ˜åŸŸã‚„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ãã€é–¢é€£æ€§ã®é«˜ã„ IPC ã‚³ãƒ¼ãƒ‰ã‚’ 3ï½5 å€‹ç¨‹åº¦ã€ä¸€è¨€èª¬æ˜ä»˜ãã§ææ¡ˆã—ã¦ãã ã•ã„ã€‚
    ãã®å¾Œã€æ¬¡ã®ã‚ˆã†ã«è¿½åŠ æƒ…å ±ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ã¦ãã ã•ã„ï¼š
    ã€Œæ¬¡ã«ã€å¯¾è±¡å›½(countries)ã€å‡ºé¡˜äºº(assignees)ã€å…¬é–‹æ—¥ä¸‹é™(publication_from)ã‚’
    ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§æ•™ãˆã¦ãã ã•ã„ã€‚ä¾‹ï¼šJP, Sony, 2021-01-01ã€
    """
    lc_messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_input)
    ]

    # LLM ã‚³ãƒ¼ãƒ«
    response = llm(lc_messages)
    ai_content = response.content.strip()

    # AI å¿œç­”ã‚’ä¼šè©±å±¥æ­´ã«è¿½åŠ ãƒ»è¡¨ç¤º
    st.session_state.messages.append({"role": "assistant", "content": ai_content})
    with st.chat_message("assistant"):
        st.markdown(ai_content)

    # IPC ã‚³ãƒ¼ãƒ‰éƒ¨åˆ†ã‚’æ­£è¦è¡¨ç¾ã§æŠ½å‡º
    codes = re.findall(r"[A-Z]\d{2}[A-Z]?\s*\d{1,2}/\d{1,2}", ai_content)
    unique_codes = []
    for code in codes:
        code_clean = code.replace(" ", "")
        if code_clean not in unique_codes:
            unique_codes.append(code_clean)
    st.session_state.ipc_candidates = unique_codes
    st.session_state.ipc_codes = unique_codes  # IPCã‚³ãƒ¼ãƒ‰ã‚’æ¤œç´¢ç”¨ã«ã‚‚ã‚»ãƒƒãƒˆ

    # è¿½åŠ æƒ…å ±å¾…ã¡ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
    st.session_state.expect_search_params = True

# --------------------------------------------
# 7. é–¢æ•°å®šç¾©: æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”¨ JSON ã‚’ç”Ÿæˆã™ã‚‹ ï¼ˆLLM ã«ãƒ‘ãƒ¼ã‚¹ã‚’ä»»ã›ã‚‹ç‰ˆï¼‰
# --------------------------------------------
def finalize_search_parameters(user_input: str):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ï¼ˆè‡ªç”±å½¢å¼ï¼‰ã‚’ LLM ã«æ¸¡ã—ã€'countries', 'assignees', 'publication_from' ã‚’
    æ¨æ¸¬ã—ã¦ã‚‚ã‚‰ã„ã€ã•ã‚‰ã« ipc_candidates ã¨çµ„ã¿åˆã‚ã›ã¦æœ€çµ‚ JSON ã‚’ç”Ÿæˆãƒ»è¡¨ç¤ºã—ã¾ã™ã€‚
    """
    # ä¼šè©±å±¥æ­´ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ã‚’è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": user_input})

    # â‘ ï¼šã¾ãš LLM ã«ã€Œãƒ‘ãƒ¼ã‚¹ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ã‚’ç”Ÿæˆ
    parse_prompt = f"""
    æ¬¡ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’è§£æã—ã€ä»¥ä¸‹ã®ã‚­ãƒ¼ã‚’å«ã‚€ JSON ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
    ãƒ»countries: å›½ã‚³ãƒ¼ãƒ‰ (ä¾‹: æ—¥æœ¬â†’\"JP\", ã‚¢ãƒ¡ãƒªã‚«â†’\"US\", ä¸­å›½â†’\"CN\" ç­‰)
    ãƒ»assignees: å‡ºé¡˜äººå (ãã®ã¾ã¾æ–‡å­—åˆ—)
    ãƒ»publication_from: å…¬é–‹æ—¥ä¸‹é™ã‚’ \"YYYY-MM-DD\" å½¢å¼ã§æŒ‡å®š (ä¾‹: \"2021å¹´ä»¥é™\"â†’\"2021-01-01\")
    ä½™è¨ˆãªèª¬æ˜ã¯ä¸€åˆ‡ä¸è¦ã§ã€å¿…ãšç´”ç²‹ã« JSON ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã ã‘ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

    ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›:
    \"\"\"{user_input}\"\"\"
    """

    # LLMå‘¼ã³å‡ºã—ï¼ˆãƒ‘ãƒ¼ã‚¹ç”¨ï¼‰
    parse_response = llm([SystemMessage(content=parse_prompt)])
    try:
        # LLM ã®å‡ºåŠ›ã‚’ JSON ãƒ‘ãƒ¼ã‚¹ã—ã¦ dict ã«å¤‰æ›
        parsed = json.loads(parse_response.content.strip())
    except json.JSONDecodeError:
        # ã‚‚ã— JSON åŒ–ã«å¤±æ•—ã—ãŸã‚‰ã€å†åº¦æ˜ç¢ºãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’è¦æ±‚
        follow_up = (
            "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚å…¥åŠ›ã®å½¢å¼ãŒã†ã¾ãè§£é‡ˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\n"
            "ã€Œcountries, assignees, publication_fromã€ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§æ•™ãˆã¦ãã ã•ã„ã€‚"
            "ä¾‹: JP, Sony, 2021-01-01"
        )
        st.session_state.messages.append({"role": "assistant", "content": follow_up})
        with st.chat_message("assistant"):
            st.markdown(follow_up)
        return

    # â‘¡ï¼šJSON ã‹ã‚‰å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å–å¾—
    countries = parsed.get("countries", [])
    assignees = parsed.get("assignees", [])
    publication_from = parsed.get("publication_from", "")

    # â‘¢ï¼šæ—¢å­˜ã® ipc_candidates ã¨åˆæˆã—ã¦æœ€çµ‚å‡ºåŠ›ã‚’ä½œã‚‹
    result = {
        "ipc_codes": st.session_state.ipc_codes,
        "countries": countries,
        "assignees": assignees,
        "publication_from": publication_from
    }
    json_result = json.dumps(result, ensure_ascii=False, indent=2)
    # â‘£ï¼šç”»é¢è¡¨ç¤ºç”¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    final_message = (
        "ä»¥ä¸‹ãŒæœ€çµ‚çš„ãªæ¤œç´¢æ¡ä»¶ã§ã™ã€‚\n"
        f"```json\n{json_result}"
    )
    st.session_state.messages.append({"role": "assistant", "content": final_message})
    with st.chat_message("assistant"):
        st.markdown(final_message)
    # ãƒ‘ãƒ¼ã‚¹å¾…ã¡ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
    st.session_state.expect_search_params = False
    # æ¤œç´¢æ¡ä»¶ãŒç¢ºå®šã—ãŸã®ã§search_readyã‚’Trueã«
    st.session_state.search_ready = True

# --------------------------------------------
# 8. é–¢æ•°å®šç¾©: æŠ€è¡“åˆ†é‡ã‚„ã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯ã‚’ææ¡ˆã™ã‚‹
# --------------------------------------------
def suggest_technologies(user_input: str):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã«å¯¾ã—ã€é–¢é€£æ€§ã®é«˜ã„æŠ€è¡“åˆ†é‡ã‚„ã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯ã‚’è‡ªç„¶æ–‡ã§ 2ï½4 é …ç›®ç¨‹åº¦ææ¡ˆã™ã‚‹ã€‚
    IPCã‚³ãƒ¼ãƒ‰ã«ã¯ä¸€åˆ‡è¨€åŠã—ãªã„ã€‚
    """
    st.session_state.messages.append({"role": "user", "content": user_input})
    system_prompt = """
    ã‚ãªãŸã¯ã€Œç‰¹è¨±èª¿æŸ»ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸæŠ€è¡“é ˜åŸŸã‚„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«å¯¾ã—ã€
    é–¢é€£æ€§ã®é«˜ã„æŠ€è¡“åˆ†é‡ã‚„ã‚µãƒ–ãƒˆãƒ”ãƒƒã‚¯ã‚’ 2ã€œ4 é …ã€è‡ªç„¶ãªæ—¥æœ¬èªã§ææ¡ˆã—ã¦ãã ã•ã„ã€‚IPCã‚³ãƒ¼ãƒ‰ã‚„ç‰¹è¨±åˆ†é¡ç•ªå·ã«ã¯è¨€åŠã›ãšã€
    ã‚¯ãƒªãƒ¼ãƒ³ã«æŠ€è¡“çš„è¦–ç‚¹ã®ã¿ã§å›ç­”ã—ã¾ã™ã€‚

    ä¾‹ï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œé€†æµ¸é€è†œã®æ©Ÿæ¢°å­¦ç¿’ã€ã¨å…¥åŠ›ã—ãŸå ´åˆã€
     1. é€†æµ¸é€è†œãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã‘ã‚‹é‹è»¢æ¡ä»¶æœ€é©åŒ–ã®ãŸã‚ã®æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é–‹ç™º
     2. ã‚»ãƒ³ã‚µãƒ¼åé›†ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸè†œæ±šæŸ“æ¤œçŸ¥ãŠã‚ˆã³äºˆæ¸¬æŠ€è¡“
     3. AIã‚’æ´»ç”¨ã—ãŸè†œè£½é€ å·¥ç¨‹ã§ã®ææ–™é¸å®šã¨å“è³ªç®¡ç†
    """
    lc_messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_input)
    ]
    response = llm(lc_messages)
    ai_content = response.content.strip()
    st.session_state.messages.append({"role": "assistant", "content": ai_content})
    with st.chat_message("assistant"):
        st.markdown(ai_content)
    # è¿½åŠ è³ªå•ã‚’ä¿ƒã™
    follow_up = "ä¸Šè¨˜ã®ä¸­ã§ç‰¹ã«èª¿æŸ»ã—ãŸã„å†…å®¹ã‚„ã€ã•ã‚‰ã«å…·ä½“çš„ãªæŠ€è¡“ãƒ†ãƒ¼ãƒãŒã‚ã‚Œã°ã”è¨˜å…¥ãã ã•ã„ã€‚"
    st.session_state.messages.append({"role": "assistant", "content": follow_up})
    with st.chat_message("assistant"):
        st.markdown(follow_up)
    st.session_state.expect_tech_suggestion = False
    st.session_state.tech_suggested = True

# --------------------------------------------
# 9. ä¼šè©±å±¥æ­´ã‚’ç”»é¢ã«è¡¨ç¤º
# --------------------------------------------
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --------------------------------------------
# 10. ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
# --------------------------------------------
user_input = st.chat_input("å…¥åŠ›ã—ã¦ãã ã•ã„â€¦")

if user_input:
    if st.session_state.expect_tech_suggestion:
        # æŠ€è¡“æ·±æ˜ã‚Šã‚¹ãƒ†ãƒƒãƒ—
        suggest_technologies(user_input)
    elif not st.session_state.ipc_candidates:
        # IPCå€™è£œç”Ÿæˆã‚¹ãƒ†ãƒƒãƒ—
        generate_ipc_candidates(user_input)
    elif st.session_state.expect_search_params:
        # æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆã‚¹ãƒ†ãƒƒãƒ—
        finalize_search_parameters(user_input)
    else:
        # æ–°è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›æ™‚ã®ãƒªã‚»ãƒƒãƒˆ
        st.session_state.ipc_candidates = []
        st.session_state.expect_search_params = False
        st.session_state.expect_tech_suggestion = True
        st.session_state.tech_suggested = False
        suggest_technologies(user_input)

# --- Streamlit UIã®ç¶šã ---
# æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿JSONãŒç”Ÿæˆã•ã‚ŒãŸã‚‰æ¤œç´¢ãƒ»ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ»ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ»è¡¨ç¤º
if st.session_state.get("search_ready", False):
    params = {
        "ipc_codes": st.session_state.ipc_codes,
        "countries": st.session_state.countries,
        "assignees": st.session_state.assignees,
        "publication_from": st.session_state.publication_from
    }
    st.markdown("### ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿æ¤œç´¢ãƒ»ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ»é¡ä¼¼åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    if st.button("ç‰¹è¨±æ¤œç´¢ãƒ»é¡ä¼¼åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°å®Ÿè¡Œ"):
        with st.spinner("BigQueryã‹ã‚‰ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºä¸­..."):
            df = search_patents_by_params(params)
        if df.empty:
            st.warning("è©²å½“ã™ã‚‹ç‰¹è¨±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.session_state["search_df"] = df  # â† ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
            st.success(f"{len(df)}ä»¶ã®ç‰¹è¨±ã‚’å–å¾—ã—ã¾ã—ãŸã€‚ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ»ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
            st.markdown("#### å–å¾—ç‰¹è¨±ä¸€è¦§ï¼ˆæ¤œç´¢æ¡ä»¶ã«åˆè‡´ã—ãŸã‚‚ã®ï¼‰")
            st.dataframe(df)
    # --- ã“ã“ã‹ã‚‰ã¯å¸¸ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®dfã‚’å‚ç…§ ---
    df = st.session_state.get("search_df")
    if df is not None and not df.empty:
        st.markdown("#### æ¤œç´¢æ„å›³ã‚„è¿½åŠ ã‚¯ã‚¨ãƒªï¼ˆãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦è¨ˆç®—ç”¨ï¼‰")
        st.info("ã“ã®æ¬„ã«ã¯ã€çŸ¥ã‚ŠãŸã„å†…å®¹ã€ã€é‡è¦–ã—ãŸã„è¦³ç‚¹ã€ã€è¿½åŠ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ãªã©ã‚’è‡ªç„¶æ–‡ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ä¾‹ï¼šAIã«ã‚ˆã‚‹æ°´è³ªç•°å¸¸æ¤œçŸ¥ã®æœ€æ–°æŠ€è¡“ ãªã©")
        query_text = st.text_input("æ¤œç´¢æ„å›³ã‚„è¿½åŠ ã‚¯ã‚¨ãƒªï¼ˆãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼åº¦è¨ˆç®—ç”¨ï¼‰", key="query_text")
        if st.button("é¡ä¼¼åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°å®Ÿè¡Œ", key="rank_button") and query_text:
            try:
                texts = df["abstract"].fillna("").tolist()
                if not any(texts):
                    st.warning("ç‰¹è¨±è¦ç´„ï¼ˆabstractï¼‰ãŒç©ºã®ãŸã‚ã€é¡ä¼¼åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
                else:
                    idx, sims = rank_by_similarity(query_text, texts, openai_api_key)
                    df_ranked = df.iloc[idx].copy()
                    df_ranked["similarity"] = sims[idx]
                    st.session_state["df_ranked"] = df_ranked  # ãƒ©ãƒ³ã‚­ãƒ³ã‚°çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                    st.session_state["explanations"] = None  # è§£èª¬ãƒªã‚»ãƒƒãƒˆ
                    st.dataframe(df_ranked)
                    csv = df_ranked.to_csv(index=False).encode("utf-8-sig")
                    st.download_button("CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv, "results.csv", "text/csv", key="csv_download")
            except Exception as e:
                st.error(f"é¡ä¼¼åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

        # --- ãƒ©ãƒ³ã‚­ãƒ³ã‚°çµæœãŒã‚ã‚Œã°Nä»¶è§£èª¬UIã‚’å¸¸ã«è¡¨ç¤º ---
        df_ranked = st.session_state.get("df_ranked")
        if df_ranked is not None and not df_ranked.empty:
            st.markdown("#### ä¸Šä½Nä»¶ã®ç‰¹è¨±ã‚’é¸æŠã—ã€æ—¥æœ¬èªã§è§£èª¬")
            n_max = min(10, len(df_ranked))
            if "topn" not in st.session_state:
                st.session_state["topn"] = min(3, n_max)
            n = st.number_input("è§£èª¬ã—ãŸã„ä¸Šä½ä»¶æ•° (N)", min_value=1, max_value=n_max, value=st.session_state["topn"], step=1, key="topn")
            if st.button("é¸æŠã—ãŸNä»¶ã‚’æ—¥æœ¬èªã§è§£èª¬", key="explain_button"):
                topN_df = df_ranked.head(n)
                explanations = []
                import openai
                client = openai.OpenAI(api_key=openai_api_key)
                for i, row in topN_df.iterrows():
                    jp_prompt = (
                        "ä»¥ä¸‹ã¯ç‰¹è¨±ã®è¦ç´„ã§ã™ã€‚å°‚é–€ç”¨èªã‚‚åˆ†ã‹ã‚Šã‚„ã™ãã€200å­—ç¨‹åº¦ã§æ—¥æœ¬èªã§è§£èª¬ã—ã¦ãã ã•ã„ã€‚\n"
                        "---\n"
                        f"{row['abstract']}"
                    )
                    try:
                        response = client.chat.completions.create(
                            model="gpt-4o",
                            messages=[{"role": "system", "content": jp_prompt}]
                        )
                        jp_summary = response.choices[0].message.content.strip()
                    except Exception as e:
                        jp_summary = f"è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}"
                    explanations.append({"title": row['title'], "summary": jp_summary})
                st.session_state["explanations"] = explanations
            # --- è§£èª¬çµæœãŒã‚ã‚Œã°è¡¨ç¤º ---
            explanations = st.session_state.get("explanations")
            if explanations:
                for i, ex in enumerate(explanations, 1):
                    st.markdown(f"**{i}ä»¶ç›®: {ex['title']}**")
                    st.info(ex["summary"])
